{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17211679-acc1-4229-9eab-b16f9d09e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import wandb\n",
    "\n",
    "from m2_utilities.load_data import load_trajectories\n",
    "from m2_utilities.preprocessor import Preprocessor\n",
    "from m2_utilities.qwen import load_qwen, train\n",
    "from m2_utilities.lora import apply_lora\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2d7eac-8278-47ac-b6ec-b7335ea0952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4674a1a0-39c1-4c70-9300-6d48ac1a57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_RANK = 4\n",
    "apply_lora(model, LORA_RANK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5dd83-ada8-4d03-8431-1527c3cfa9a3",
   "metadata": {},
   "source": [
    "### Preprocessing Trajectories to Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b77855-009c-4c5a-9fbf-f54ae6c31ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "trajectories = load_trajectories(\"data/lotka_volterra_data.h5\")\n",
    "\n",
    "# Train/validation\n",
    "N_TRAIN = 700\n",
    "N_VAL = 150\n",
    "\n",
    "train = trajectories[:N_TRAIN]\n",
    "val = trajectories[N_TRAIN: N_TRAIN + N_VAL]\n",
    "\n",
    "# Preprocessing and chunking\n",
    "DECIMALS = 2\n",
    "preprocessor = Preprocessor(DECIMALS)\n",
    "train_input_ids = preprocessor.encode(train, chunk=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d4080-48e7-4523-b2ae-0293bc49f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising data loaders\n",
    "BATCH_SIZE = 4\n",
    "train_dataset = TensorDataset(train_input_ids)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d01a3-8268-46a8-8281-79f523b38a6d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mat2128\u001b[0m (\u001b[33mat2128-university-of-cambridge\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/user/at2128/hpc-work/M2-Coursework/notebooks/wandb/run-20250319_185649-74sini1d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework/runs/74sini1d' target=\"_blank\">classic-oath-3</a></strong> to <a href='https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework' target=\"_blank\">https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework/runs/74sini1d' target=\"_blank\">https://wandb.ai/at2128-university-of-cambridge/M2%20Coursework/runs/74sini1d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR = 1e-5\n",
    "config = {\"Learning Rate\": LR,\n",
    "          \"Batch Size\": BATCH_SIZE, \n",
    "          \"Decimals\": DECIMALS,\n",
    "          \"Lora Rank\": LORA_RANK}\n",
    "wandb.init(project=\"M2 Coursework\", config=config)\n",
    "wandb.watch(model, log=\"all\", log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac9be7c-8f6a-4caf-a039-056bfddc6701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Steps 0:   6%|â–Œ         | 49/875 [01:12<20:25,  1.48s/it, loss=3.32] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/m2_utilities/qwen.py:87\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, eval_interval, max_steps, learning_rate, wandb)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Evaluating on validation dataset\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m steps % eval_interval == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     val_loss, val_flops = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_flops\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     total_flops += val_flops\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# Logging to wandb\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/m2_utilities/qwen.py:35\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(model, test_loader, calc_flops)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (batch,) \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m         loss = outputs.loss\n\u001b[32m     37\u001b[39m         test_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/torch/nn/modules/module.py:1806\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1804\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1809\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/wandb/integration/torch/wandb_torch.py:113\u001b[39m, in \u001b[36mTorchHistory.add_log_parameters_hook.<locals>.<lambda>\u001b[39m\u001b[34m(mod, inp, outp)\u001b[39m\n\u001b[32m    110\u001b[39m log_track_params = log_track_init(log_freq)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    112\u001b[39m     hook = module.register_forward_hook(\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m mod, inp, outp: \u001b[43mparameter_log_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_track_params\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     )\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m._hook_handles[\u001b[33m\"\u001b[39m\u001b[33mparameters/\u001b[39m\u001b[33m\"\u001b[39m + prefix] = hook\n\u001b[32m    118\u001b[39m     module._wandb_hook_names.append(\u001b[33m\"\u001b[39m\u001b[33mparameters/\u001b[39m\u001b[33m\"\u001b[39m + prefix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/wandb/integration/torch/wandb_torch.py:108\u001b[39m, in \u001b[36mTorchHistory.add_log_parameters_hook.<locals>.parameter_log_hook\u001b[39m\u001b[34m(module, input_, output, log_track)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    107\u001b[39m     data = parameter\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_tensor_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparameters/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rds/user/at2128/hpc-work/M2-Coursework/env_site/lib64/python3.11/site-packages/wandb/integration/torch/wandb_torch.py:214\u001b[39m, in \u001b[36mTorchHistory.log_tensor_stats\u001b[39m\u001b[34m(self, tensor, name)\u001b[39m\n\u001b[32m    211\u001b[39m flat = \u001b[38;5;28mself\u001b[39m._remove_infs_nans(flat)\n\u001b[32m    213\u001b[39m tmin = flat.min().item()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m tmax = \u001b[43mflat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.item()\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse_zeros:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# If we've got zeros to add in, make sure zero is in the hist range.\u001b[39;00m\n\u001b[32m    217\u001b[39m     tmin = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tmin > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m tmin\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, learning_rate=LR, eval_interval=50, wandb=wandb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
