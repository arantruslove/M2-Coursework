{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78c916e-fdd0-499b-9360-fc43ab1e422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import m2_utilities.flops as flops\n",
    "from m2_utilities.model.qwen import load_qwen\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d4f859-644e-4aaa-939a-af62c7be3ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7820ddb-e716-485f-94dc-7461159cf2ef",
   "metadata": {},
   "source": [
    "### Single Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d775204c-85a6-4cb3-93dc-ec692e57e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPS: 1.6955e+12\n"
     ]
    }
   ],
   "source": [
    "N_TOKENS = 512\n",
    "\n",
    "n_flops = flops.compute_flops(N_TOKENS, backpropagate=True)\n",
    "print(f\"Total FLOPS: {n_flops:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3482c5a",
   "metadata": {},
   "source": [
    "### Generate 20 Given Context Length of 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dfd8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPS: 5.8470e+14\n"
     ]
    }
   ],
   "source": [
    "N_CONTEXT = 10\n",
    "N_GENERATE = 90\n",
    "\n",
    "n_flops = flops.compute_flops_gen(N_CONTEXT, N_GENERATE, batch_size=150)\n",
    "print(f\"Total FLOPS: {n_flops:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732afb5-2bc5-498c-82b1-f7acc7135eb8",
   "metadata": {},
   "source": [
    "### Adding Poisitional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd0a7f3-59f7-44af-a214-c83924566a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embbeding Layer: 4.59e+05\n"
     ]
    }
   ],
   "source": [
    "n_flops = flops.embedding(N_TOKENS, hidden_size=896)\n",
    "print(f\"Embbeding Layer: {n_flops:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204c83d-da4c-4c36-97a2-cf1c02a703c4",
   "metadata": {},
   "source": [
    "### All Self-Attention Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99235dc5-2c00-4900-8821-1dc459fdf6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Block: 1.77e+10\n",
      "24 Blocks: 4.25e+11\n"
     ]
    }
   ],
   "source": [
    "N_LAYERS = 24\n",
    "n_flops = flops.block(N_TOKENS, n_heads=14, hidden_size=896, intermediate_size=4864)\n",
    "print(f\"Single Block: {n_flops:.2e}\")\n",
    "print(f\"{N_LAYERS} Blocks: {N_LAYERS * n_flops:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbe2b7-9fc1-47a7-994d-d44c1cffb7aa",
   "metadata": {},
   "source": [
    "### Breakdown of a Single Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003cf7f0-2277-43fb-ac70-773daca1a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN: 1.34e+10\n",
      "MHSA: 4.27e+09\n",
      "RMSNorm: 5.97e+06\n",
      "Residual: 4.59e+05\n"
     ]
    }
   ],
   "source": [
    "n_flops = flops.ffn(N_TOKENS, hidden_size=896, intermediate_size=4864)\n",
    "print(f\"FFN: {n_flops:.2e}\")\n",
    "\n",
    "n_flops = flops.multi_head_self_attention(N_TOKENS, n_heads=14, hidden_size=896)\n",
    "print(f\"MHSA: {n_flops:.2e}\")\n",
    "\n",
    "n_flops = flops.rms_norm(N_TOKENS, hidden_size=896)\n",
    "print(f\"RMSNorm: {n_flops:.2e}\")\n",
    "\n",
    "n_flops = flops.add_residual(N_TOKENS, hidden_size=896)\n",
    "print(f\"Residual: {n_flops:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3fd5e-7b99-4277-8aa9-834018f310e4",
   "metadata": {},
   "source": [
    "### Post Self-Attention Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9304559-c92b-4d7f-b6a8-44889d77edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Linear Transform: 1.39e+11\n",
      "Final Softmax: 9.33e+08\n"
     ]
    }
   ],
   "source": [
    "n_flops = flops.final_linear(N_TOKENS, hidden_size=896, vocab_size=151936)\n",
    "print(f\"Final Linear Transform: { n_flops:.2e}\")\n",
    "\n",
    "n_flops = flops.softmax(N_TOKENS, vector_size=151936)\n",
    "print(f\"Final Softmax: {n_flops:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
